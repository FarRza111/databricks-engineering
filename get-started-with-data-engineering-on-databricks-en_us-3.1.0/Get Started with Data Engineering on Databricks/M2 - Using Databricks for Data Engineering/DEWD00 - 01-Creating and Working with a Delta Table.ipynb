{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "5e3abadb-0f9d-416c-8a42-968df1896811",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "<div style=\"text-align: center; line-height: 0; padding-top: 9px;\">\n",
    "  <img\n",
    "    src=\"https://databricks.com/wp-content/uploads/2018/03/db-academy-rgb-1200px.png\"\n",
    "    alt=\"Databricks Learning\"\n",
    "  >\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9faf24df-a4da-48f9-af0b-7b4a579b2dd2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Creating and Working with a Delta Table \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "0eda177f-9c04-44fc-a2ba-0d22162c20af",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## REQUIRED - SELECT CLASSIC COMPUTE\n",
    "\n",
    "Before executing cells in this notebook, please select your classic compute cluster in the lab. Be aware that **Serverless** is enabled by default.\n",
    "\n",
    "Follow these steps to select the classic compute cluster:\n",
    "\n",
    "\n",
    "1. Navigate to the top-right of this notebook and click the drop-down menu to select your cluster. By default, the notebook will use **Serverless**.\n",
    "\n",
    "2. If your cluster is available, select it and continue to the next cell. If the cluster is not shown:\n",
    "\n",
    "   - Click **More** in the drop-down.\n",
    "\n",
    "   - In the **Attach to an existing compute resource** window, use the first drop-down to select your unique cluster.\n",
    "\n",
    "**NOTE:** If your cluster has terminated, you might need to restart it in order to select it. To do this:\n",
    "\n",
    "1. Right-click on **Compute** in the left navigation pane and select *Open in new tab*.\n",
    "\n",
    "2. Find the triangle icon to the right of your compute cluster name and click it.\n",
    "\n",
    "3. Wait a few minutes for the cluster to start.\n",
    "\n",
    "4. Once the cluster is running, complete the steps above to select your cluster."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "36156190-8fd2-499f-8e1f-9fc4116d4b7f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Classroom Setup\n",
    "\n",
    "Run the following cell to configure your working environment for this course.\n",
    "\n",
    "**NOTE:** The `DA` object is only used in Databricks Academy courses and is not available outside of these courses. It will dynamically reference the information needed to run the course."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "bf34c0fe-61cf-42af-85a2-4d5becb540ea",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%run ../Includes/Classroom-Setup-01"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "5fe7e343-6b05-45a7-a63a-6d0709924d39",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## A. Explore your Catalog\n",
    "\n",
    "**The Unity Catalog object model**\n",
    "\n",
    "In Unity Catalog, all metadata is registered in a metastore. The hierarchy of database objects in any Unity Catalog metastore is divided into three levels, represented as a three-level namespace (catalog.schema.table-etc) when you reference tables, views, volumes, models, and functions.\n",
    "\n",
    "![unity_catalog_object_model](../Includes/images/unity_catalog_object_model.png)\n",
    "\n",
    "\n",
    "For more information check out [What is Unity Catalog?](https://docs.databricks.com/en/data-governance/unity-catalog/index.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c441603f-df23-4e88-9a28-8602a8981a04",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "####1. Viewing the Catalog and Schema\n",
    "Complete the following to manually view the course catalog **dbacademy** and your schema:\n",
    "\n",
    "- Select the Catalog icon ![catalog_icon](../Includes/images/catalog_icon.png) in the left navigation bar. \n",
    "\n",
    "- You should see your catalog name(**dbacademy**)\n",
    "\n",
    "- Expand the **dbacademy** catalog. Within the catalog, you should see a variety of schemas (databases).\n",
    "\n",
    "- Find your specific schema (begins with **labuser**). You can locate your schema in the classroom setup notes in the first cell.\n",
    "\n",
    "- Expand your schema. Notice that your schema only contains a volume named **myfiles**.\n",
    "\n",
    "- Expand your volume. The volume should contain a single CSV file named **employees.csv**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "06973390-e76b-443e-b4e4-21a8862af322",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "####2. Defaulting Catalog and Schema\n",
    "Execute the cells to set the current catalog to **dbacademy** and the current schema to your specific schema. This configuration avoids the need to use a two-level naming convention (catalog.schema) in your queries. The SELECT statement will display the name of your current catalog and schema. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "07a7aa5e-0bbc-449b-a99a-67e566b30ffb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "SELECT DA.schema_name -- Precreated SQL variable pointing to your unique schema"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "93afa0a3-52d9-43be-a710-d60c31192e65",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Let's modify our default catalog and schema using the `USE CATALOG` and `USE SCHEMA` statements. This eliminates the need to specify the three-level name for objects in your **labuser** schema (i.e., catalog.schema.object).\n",
    "\n",
    "  - `USE CATALOG` – Sets the current catalog.\n",
    "\n",
    "  - `USE SCHEMA` – Sets the current schema.\n",
    "\n",
    "    **NOTE:** Since our dynamic schema name is stored in the SQL variable `DA.schema_name` as a string, we will need to use the `IDENTIFIER` clause to interpret the constant string in our variable as a schema name. The `IDENTIFIER` clause can interpret a constant string as any of the following:\n",
    "    - Relation (table or view) name\n",
    "    - Function name\n",
    "    - Column name\n",
    "    - Field name\n",
    "    - Schema name\n",
    "    - Catalog name\n",
    "\n",
    "    [IDENTIFIER clause documentation](https://docs.databricks.com/aws/en/sql/language-manual/sql-ref-names-identifier-clause?language=SQL)\n",
    "\n",
    "Run the following cell to set and view your default catalog and schema. Confirm that your default catalog is **dbacademy** and your schema is **labuser** (this uses the `DA.schema_name` variable created in the classroom setup script).\n",
    "\n",
    "**NOTE:** Alternatively, you can simply add your schema name without using the `IDENTIFIER` clause.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "40cd4842-e0b1-47e0-98dc-5adde930f38c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "USE CATALOG dbacademy;\n",
    "USE SCHEMA IDENTIFIER(DA.schema_name);\n",
    "\n",
    "SELECT current_catalog(), current_schema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "450bda38-e942-4b3f-8f63-40b38e81af9e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "####3. Describing the Schema \n",
    "Use the [DESCRIBE SCHEMA EXTENDED](https://docs.databricks.com/en/sql/language-manual/sql-ref-syntax-aux-describe-schema.html) statement to display the metadata and properties of your schema."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ab1ed554-7ae3-47bb-8ffb-fc3c12cf62a2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "DESCRIBE SCHEMA EXTENDED IDENTIFIER(DA.schema_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "01dad30e-c58f-44f8-a537-9070ee39313a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "####4. Show Table\n",
    "Use the [SHOW TABLES](https://docs.databricks.com/en/sql/language-manual/sql-ref-syntax-aux-show-tables.html) statement to display the available tables in your schema. You will notice that there are currently no tables available in your schema."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "6dad9fc7-f2c6-455b-a0ec-f5474f94b1d6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "SHOW TABLES;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "2d9f70a5-9d54-4f88-abb1-43401ceeaf23",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "####5. Show Volumes\n",
    "Use the [SHOW VOLUMES](https://docs.databricks.com/en/sql/language-manual/sql-ref-syntax-aux-show-volumes.html) statement to list all of the volumes available in your schema. Notice that you have a single volume available, **myfiles**.\n",
    "\n",
    "\n",
    "**NOTE**: Volumes are Unity Catalog objects representing a logical volume of storage in a cloud object storage location. Volumes provide capabilities for accessing, storing, governing, and organizing files. While tables provide governance over tabular datasets, volumes add governance over non-tabular datasets. \n",
    "\n",
    "You can use volumes to store and access files in any format, including structured, semi-structured, and unstructured data.\n",
    "\n",
    "[What are Unity Catalog volumes?](https://docs.databricks.com/en/volumes/index.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "5a39502f-3499-427a-aecc-cf833fe86bae",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "SHOW VOLUMES;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c6e8c737-607b-4a18-a008-6b3062d2b3dd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "####6. Listing files/data in Volumes\n",
    "Use the LIST statement to list all of the files in the **myfiles** volume. Notice that the volume only has the **employees.csv** file. It contains information about current employees. \n",
    "\n",
    "When interacting with data in volumes, you use the path provided by Unity Catalog, which always has the following format: `/Volumes/catalog_name/schema_name/volume_name/`.\n",
    "\n",
    "For more information on exploring directories and data files managed with Unity Catalog volumes, check out the [Explore storage and find data files](https://docs.databricks.com/en/discover/files.html)  documentation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "6e9e5e55-a499-4e7e-aa11-c57bfbd0f722",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "spark.sql(f\"LIST '/Volumes/dbacademy/{DA.schema_name}/myfiles'\").display()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d5441a02-5df0-439c-a4ad-0f7aa2beddab",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## B. Create a Delta Table from a CSV File\n",
    "\n",
    "All saved tables on Databricks are Delta tables by default. Whether you’re using Apache Spark DataFrames or SQL, you get all the benefits of Delta Lake just by saving your data to the lakehouse with default settings."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "015cd8f1-c2c2-4515-b314-8dc88514e1c9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "1. Query the **employees.csv** file directly using SQL to view the file. Notice that the query returns a view of the CSV file with the headers as the first row of data.\n",
    "\n",
    "**NOTE**: This syntax is specific to Spark SQL and allows you to read files directly without explicitly loading them into a table first. You specify the file format and enclose the file path in **backticks**. This method works for various file types.\n",
    "\n",
    "*SELECT * FROM \\<file_format>.\\`/path/to/file`;*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "615a11f7-7d16-4137-9f14-a054402b0c9d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "spark.sql(f'''\n",
    "SELECT *\n",
    "FROM csv.`/Volumes/dbacademy/{DA.schema_name}/myfiles/` \n",
    "''').display()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f170032b-57fe-4777-8e85-b3a500d79918",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "2. You can use the *text* file format to view files as strings in a column. This enables you to view the contents of the file. Notice that the first row contains the column names and the fields are separated by commas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "0515a5cc-ca05-4335-b191-c89b22f4b90e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "spark.sql(f'''\n",
    "SELECT * \n",
    "FROM text.`/Volumes/dbacademy/{DA.schema_name}/myfiles/`\n",
    "''').display()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "05dbdf63-0a24-400a-8cb8-8c0f039f0da2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "3. With SQL you can use the [read_files](https://docs.databricks.com/en/sql/language-manual/functions/read_files.html) table-valued function to read the CSV file into tabular form and apply specific options to modify how the file is read. \n",
    "\n",
    "    Execute the query and confirm that the results show 4 employees with valid column names.\n",
    "\n",
    "**NOTE**: A rescued data column is provided by default to rescue any data that doesn’t match the schema."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "0fb0a14a-57d2-4480-8252-e6f2930d977e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "SELECT *\n",
    "FROM read_files(\n",
    "  '/Volumes/dbacademy/' || DA.schema_name || '/myfiles/',\n",
    "  format => 'csv',\n",
    "  header => true,\n",
    "  inferSchema => true\n",
    "  )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "efb05fff-5bb6-4560-be0b-a234f2b22c7f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "4. Use the CREATE TABLE AS (CTAS) statement with the query from above to create a Delta table in the Lakehouse named **current_employees** using the **employees.csv** file. The table will be created in your schema.\n",
    "\n",
    "**NOTE:** The CREATE TABLE statement will create a Delta table by default."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "76e91f74-196d-47b3-9585-a3aef73e5103",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "-- Drop the table if it already exists for demonstration purposes\n",
    "DROP TABLE IF EXISTS current_employees;\n",
    "\n",
    "-- Create a Delta table using the CSV file\n",
    "\n",
    "CREATE TABLE current_employees AS\n",
    "SELECT \n",
    "  ID, \n",
    "  FirstName, \n",
    "  Country, \n",
    "  Role \n",
    "FROM read_files(\n",
    "  '/Volumes/dbacademy/' || DA.schema_name || '/myfiles/',\n",
    "  format => 'csv',\n",
    "  header => true,\n",
    "  inferSchema => true\n",
    "  );\n",
    "\n",
    "\n",
    "-- Display table\n",
    "SELECT *\n",
    "FROM current_employees;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d2025db3-b9d1-4620-a1a9-2b967597e4f4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "5. Complete the following steps to manually view the table in your schema:\n",
    "\n",
    "   a. Select the Catalog icon ![catalog_icon](../Includes/images/catalog_icon.png) in the left navigation bar. \n",
    "\n",
    "   b. Find the catalog name **dbacademy**.\n",
    "\n",
    "   c. Select the refresh icon ![refresh_icon](../Includes/images/refresh_icon.png) to refresh the catalog.\n",
    "\n",
    "   d. Expand the **dbacademy** catalog. Within the catalog you should see a variety of schemas (databases).\n",
    "\n",
    "   e. Find your schema. You can locate your schema in the classroom setup notes in the first cell. \n",
    "\n",
    "   f. Expand your schema. Notice that your schema contains **Volumes** and **Tables**.\n",
    "\n",
    "   g. Expand **Tables**. Confirm that the **current_employees** Delta table is available."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ce816f92-d886-46e1-8ccd-e9ccc374af75",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "(optional) To create a Delta table from a CSV file using Python, you can use the code below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c25e3ae2-6cbb-4116-92fe-e8cf7088a92f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#\n",
    "# Read the CSV file and create a Spark DataFrame\n",
    "#\n",
    "sdf = (spark\n",
    "       .read\n",
    "       .format(\"csv\")\n",
    "       .option('header', 'true')\n",
    "       .option('inferSchema','true')\n",
    "       .load(f'/Volumes/dbacademy/{DA.schema_name}/myfiles/')\n",
    "    )\n",
    "\n",
    "\n",
    "#\n",
    "# Create a Delta table from the Spark DataFrame\n",
    "#\n",
    "\n",
    "(sdf\n",
    " .write\n",
    " .mode(\"overwrite\")\n",
    " .format(\"delta\")\n",
    " .saveAsTable(f\"dbacademy.{DA.schema_name}.current_employees_py\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "7e2bb978-08d1-4dcf-b61e-9218fd8014b9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Read the Delta table using Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "17d24dd5-e27f-4ada-bcf2-a512eec611f8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "(spark\n",
    " .read\n",
    " .table(f\"dbacademy.{DA.schema_name}.current_employees_py\")\n",
    " .display()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "6eb38050-1ae5-4bdf-83b9-ebf8eed621c5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "6. Show the tables in your schema using Python. You should see a table named **current_employees** and **current_employees_py**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "4e263d21-cee9-4387-9f71-62b93c009bef",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "spark.catalog.listTables(f\"dbacademy.{DA.schema_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "7664b4db-5b32-4f6d-b26a-b804e6f91d32",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "7. Query the **current_employees** table to view the data. Confirm that it contains 4 rows of data with a list of current employees."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ffd930f8-a629-409d-a4ce-f0701a235251",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "SELECT * \n",
    "FROM current_employees;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "fb40cb0f-8c77-4720-9624-c8b32b27479a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "8. Use the DESCRIBE DETAIL statement to view detailed information about the **current_employees** table. View the results. \n",
    "\n",
    "    Notice the following:\n",
    "    - The **format** column indicates that the **current_employees** table has been created as a Delta table.\n",
    "    - The **location** column displays the cloud location of the table in the following format for AWS: \n",
    "        - *s3://\\<bucket-name>/\\<metastore id>/tables/\\<table id>* \n",
    "\n",
    "**NOTES:** \n",
    "    - The results of the DESCRIBE DETAIL statement includes additional information about the Delta table. For more details, refer to the [Detail schema documentation](https://docs.databricks.com/en/delta/table-details.html#detail-schema).\n",
    "    - For more information on how paths work for data managed by Unity Catalog check out the [How do paths work for data managed by Unity Catalog?](https://docs.databricks.com/en/data-governance/unity-catalog/paths.html) documentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "1e60abd8-a9b7-4663-93aa-c3f731dc6cce",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "DESCRIBE DETAIL current_employees;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a5e01df8-580d-4796-8381-2be8e076a8a1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "9. Use the [DESCRIBE EXTENDED](https://docs.databricks.com/en/sql/language-manual/sql-ref-syntax-aux-describe-table.html) statement to display detailed information about the specified columns and additional metadata for the Delta table.\n",
    "\n",
    "    Notice the following:\n",
    "    - The top portion of the results displays column metadata of the table.\n",
    "    - Scroll down the **col_name** column to find the *Type* value. Notice that the **data_type** specifies *Managed*. This indicates that Databricks manages the lifecycle and file layout for the table. Managed tables are the default table creation method.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "299ede20-dc25-443d-bbf6-cc1b37b04fd0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "DESCRIBE EXTENDED current_employees;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "591353f9-9b70-4368-ae6a-41fc7cd34653",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "10. Execute the [DESCRIBE HISTORY](https://docs.databricks.com/en/sql/language-manual/delta-describe-history.html) statement on the **current_employees** table to retrieve Delta table history.\n",
    "\n",
    "    Notice the following:\n",
    "    - The **version** column indicates the table is on version 0\n",
    "    - The **timestamp** column displays when the table was created\n",
    "    - The **operation** column shows what operation was performed.\n",
    "    - The **operationsMetrics** column display information about the number of files, number of output rows, and number of output bytes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "05475e94-6ba9-491b-8178-7deeb66820b3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "DESCRIBE HISTORY current_employees;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9bd8be01-f3d5-4c79-9cd2-74110ad71538",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## C. Insert, Update and Delete Records in the Delta Table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "bff9235c-5f9c-4505-a9bc-52d6c97176b4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "1. View the current **current_employees** table. \n",
    "\n",
    "    Notice the following in the Delta table:\n",
    "    - There are 4 columns and 4 rows\n",
    "    - The **ID** values *1111*, *2222*, *3333*, *4444* are in the table\n",
    "    - The  **Role** of **ID** *1111* is *Manager*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "87c7b6c9-3bfc-4337-abb2-f13f6f82592b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "SELECT * \n",
    "FROM current_employees;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "6d8ed7d9-5125-4a65-9575-645d16244286",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "2. Perform the following operations on the **current_employees** Delta table:\n",
    "\n",
    "   a. Insert two new employees named *Alex* and *Sanjay*. \n",
    "\n",
    "   b. Update the **Role** of employee **ID** *1111* to *Senior Manager*.\n",
    "\n",
    "   c. Delete the record of the employee with the **ID** *3333*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b1ef1033-c830-499d-a652-3a524dad9812",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "-- 1. Insert two employees into the table\n",
    "INSERT INTO current_employees \n",
    "VALUES\n",
    "    (5555, 'Alex','USA', 'Instructor'),\n",
    "    (6666, 'Sanjay','India', 'Instructor');\n",
    "\n",
    "-- 2. Update a record in the table\n",
    "UPDATE current_employees\n",
    "  SET Role = 'Senior Manager'\n",
    "  WHERE ID = 1111;\n",
    "\n",
    "-- 3. Delete a record in the table\n",
    "DELETE FROM current_employees\n",
    "  WHERE ID = 3333;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "38efcbd1-3b56-4999-93f6-64495bcfa4bf",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "3. View the data in the **current_employees** table. Notice that the table has been modified from the original version."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "932e8a23-e9a1-46c9-ac8e-1da9c340cbdc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "SELECT *\n",
    "FROM current_employees\n",
    "ORDER BY ID;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "2b7df897-0db0-44a9-b062-ed320676b25a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "4. Each operation that modifies a Delta Lake table creates a new table version. View the history of the table.\n",
    "\n",
    "    Notice the following:\n",
    "    - The table has versions 0 through 4. \n",
    "    - **Version 0** is the original table that was created.\n",
    "    - **Version 1** contains the WRITE operation that inserted two new employees.\n",
    "    - **Version 2** contains the UPDATE operation that modified the job role.\n",
    "    - **Version 3** contains the DELETE operation that removed an employee.\n",
    "    - **Version 4** contains the OPTIMIZE operation on the table. Predictive optimization is a feature in Delta Lake on Databricks that automatically optimizes Delta tables (optional feature). For more information, view the [Predictive optimization for Delta Lake\n",
    "    ](https://docs.databricks.com/en/optimizations/predictive-optimization.html) documentation.\n",
    "\n",
    "**NOTE:** The `OPTIMIZE` operation(s) might be in a different order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "fa04a2ad-8e4e-4ec3-aee8-dd1bf2d27af0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "DESCRIBE HISTORY current_employees;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b393e36e-b0b9-4035-9b23-e774fb84581e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## D. Use Time Travel to Read Previous Versions of the Delta Table\n",
    "You can use history information to audit operations, rollback a table, or query a table at a specific point in time using time travel."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "3638200f-719f-4804-9c68-b457ca7d07a0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "1. View the current version of the **current_employees** table. By default, the most recent version of the table will be used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "2aedb381-d62e-4a2c-a6ed-561dc74a6672",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "SELECT *\n",
    "FROM current_employees\n",
    "ORDER BY ID;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "7c060856-888a-4d86-8360-52564f08f59c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "2. Use time travel to view the table prior to the DELETE operation. Notice that the results show 6 employees before the record was deleted.\n",
    "\n",
    "**NOTE**: Time travel takes advantage of the power of the Delta Lake transaction log to access data that is no longer in the table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "af20b186-5800-46a2-bedd-b906c397e2ab",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "SELECT *\n",
    "FROM current_employees VERSION AS OF 2\n",
    "ORDER BY ID;\n",
    "\n",
    "-- Alternate syntax\n",
    "-- SELECT *\n",
    "-- FROM current_employees@v2\n",
    "-- ORDER BY ID;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "10029f32-979b-49c4-8a6c-2acc6201f5da",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "3. View the original table using version 0. Notice that the original 4 employees are displayed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "36157dac-9677-4c60-bc8d-e86c5899e298",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "SELECT *\n",
    "FROM current_employees VERSION AS OF 0\n",
    "ORDER BY ID;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "cb9d7f8e-87c4-4d8f-b43c-44f0da4acefb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## E. Drop the Tables\n",
    "1. Drop the Delta tables created in this demonstration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "4414ea8e-1289-4f00-837c-06ed4cce03eb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "DROP TABLE IF EXISTS current_employees;\n",
    "DROP TABLE IF EXISTS current_employees_py;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a4ed2f68-67d5-49cd-9921-6091555c9d16",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "&copy; 2026 Databricks, Inc. All rights reserved. Apache, Apache Spark, Spark, the Spark Logo, Apache Iceberg, Iceberg, and the Apache Iceberg logo are trademarks of the <a href=\"https://www.apache.org/\" target=\"_blank\">Apache Software Foundation</a>.<br/><br/><a href=\"https://databricks.com/privacy-policy\" target=\"_blank\">Privacy Policy</a> | <a href=\"https://databricks.com/terms-of-use\" target=\"_blank\">Terms of Use</a> | <a href=\"https://help.databricks.com/\" target=\"_blank\">Support</a>"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": null,
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {},
   "notebookName": "DEWD00 - 01-Creating and Working with a Delta Table",
   "widgets": {}
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
